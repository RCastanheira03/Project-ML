{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "220a53f5-72aa-425a-8792-2db1ec018545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7566, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>owner</th>\n",
       "      <th>mileage</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>torque</th>\n",
       "      <th>seats</th>\n",
       "      <th>fuel_Diesel</th>\n",
       "      <th>fuel_LPG</th>\n",
       "      <th>...</th>\n",
       "      <th>brand_Nissan</th>\n",
       "      <th>brand_Opel</th>\n",
       "      <th>brand_Peugeot</th>\n",
       "      <th>brand_Renault</th>\n",
       "      <th>brand_Skoda</th>\n",
       "      <th>brand_Tata</th>\n",
       "      <th>brand_Toyota</th>\n",
       "      <th>brand_Volkswagen</th>\n",
       "      <th>brand_Volvo</th>\n",
       "      <th>car_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488000</td>\n",
       "      <td>0.341286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655999</td>\n",
       "      <td>0.535379</td>\n",
       "      <td>0.467401</td>\n",
       "      <td>0.418743</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.435603</td>\n",
       "      <td>0.316742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.582041</td>\n",
       "      <td>0.640637</td>\n",
       "      <td>0.627256</td>\n",
       "      <td>0.498515</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.336228</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.472299</td>\n",
       "      <td>0.640276</td>\n",
       "      <td>0.493676</td>\n",
       "      <td>0.040177</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.302060</td>\n",
       "      <td>0.323773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.642808</td>\n",
       "      <td>0.601599</td>\n",
       "      <td>0.562794</td>\n",
       "      <td>0.081435</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.152797</td>\n",
       "      <td>0.316742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422550</td>\n",
       "      <td>0.559201</td>\n",
       "      <td>0.553238</td>\n",
       "      <td>0.034175</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   selling_price  km_driven  owner   mileage    engine  max_power    torque  \\\n",
       "0       0.488000   0.341286    0.0  0.655999  0.535379   0.467401  0.418743   \n",
       "1       0.435603   0.316742    1.0  0.582041  0.640637   0.627256  0.498515   \n",
       "2       0.206186   0.336228    2.0  0.472299  0.640276   0.493676  0.040177   \n",
       "3       0.302060   0.323773    0.0  0.642808  0.601599   0.562794  0.081435   \n",
       "4       0.152797   0.316742    0.0  0.422550  0.559201   0.553238  0.034175   \n",
       "\n",
       "   seats  fuel_Diesel  fuel_LPG  ...  brand_Nissan  brand_Opel  brand_Peugeot  \\\n",
       "0    5.0          1.0       0.0  ...           0.0         0.0            0.0   \n",
       "1    5.0          1.0       0.0  ...           0.0         0.0            0.0   \n",
       "2    5.0          0.0       0.0  ...           0.0         0.0            0.0   \n",
       "3    5.0          1.0       0.0  ...           0.0         0.0            0.0   \n",
       "4    5.0          0.0       0.0  ...           0.0         0.0            0.0   \n",
       "\n",
       "   brand_Renault  brand_Skoda  brand_Tata  brand_Toyota  brand_Volkswagen  \\\n",
       "0            0.0          0.0         0.0           0.0               0.0   \n",
       "1            0.0          1.0         0.0           0.0               0.0   \n",
       "2            0.0          0.0         0.0           0.0               0.0   \n",
       "3            0.0          0.0         0.0           0.0               0.0   \n",
       "4            0.0          0.0         0.0           0.0               0.0   \n",
       "\n",
       "   brand_Volvo  car_age  \n",
       "0          0.0       11  \n",
       "1          0.0       11  \n",
       "2          0.0       19  \n",
       "3          0.0       15  \n",
       "4          0.0       18  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "config_path = Path(\"../config.yaml\")\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "csv_relative_path = config[\"data\"][\"clean_data_csv\"][\"clean_data_v3_irma\"]\n",
    "csv_path = config_path.parent / csv_relative_path\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70954d4d-6ff5-43d3-a62b-fa16b0c374a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "X = df.drop(columns=[\"selling_price\"])\n",
    "y = df[\"selling_price\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8cc693-d6ea-4370-af44-c3f27ab65acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6052, 45) (1514, 45)\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e40d15-6092-4cbf-a3e3-79ff8a837992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "302a6086-fc9c-4868-a9b9-5f5edbf87a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(name, model,\n",
    "                   X_train_scaled, X_test_scaled,\n",
    "                   X_train, X_test,\n",
    "                   y_train, y_test, use_scaled=True):\n",
    "    \"\"\"\n",
    "    Train and evaluate a regression model and store results in the global results_df.\n",
    "    Automatically removes any previous entry of the same model name to avoid duplicates.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select scaled or unscaled data depending on the model\n",
    "    if use_scaled:\n",
    "        Xtr, Xte = X_train_scaled, X_test_scaled\n",
    "    else:\n",
    "        Xtr, Xte = X_train, X_test\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtr, y_train)\n",
    "    y_pred = model.predict(Xte)\n",
    "\n",
    "    # Compute metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Update global results without duplicates\n",
    "    global results_df\n",
    "    results_df = results_df[results_df[\"Model\"] != name]  # remove old row if it exists\n",
    "\n",
    "    new_row = pd.DataFrame([{\n",
    "        \"Model\": name,\n",
    "        \"MAE\": mae,\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2\n",
    "    }])\n",
    "\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "    # Display summary in console\n",
    "    print(f\"{name} -> R²: {r2:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | MSE: {mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6999655-ad2a-40a3-949c-83a964fc8492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (sin escalar)\n",
      "MAE: 0.05\n",
      "MSE: 0.00\n",
      "RMSE: 0.06\n",
      "R²: 0.8886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Create model KNN before scaling\n",
    "knn_raw = KNeighborsRegressor()\n",
    "\n",
    "# Train and predict \n",
    "knn_raw.fit(X_train, y_train)\n",
    "y_pred_knn_raw = knn_raw.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "mae_raw = mean_absolute_error(y_test, y_pred_knn_raw)\n",
    "mse_raw = mean_squared_error(y_test, y_pred_knn_raw)\n",
    "rmse_raw = np.sqrt(mse_raw)\n",
    "r2_raw = r2_score(y_test, y_pred_knn_raw)\n",
    "\n",
    "print(\"KNN (sin escalar)\")\n",
    "print(f\"MAE: {mae_raw:.2f}\")\n",
    "print(f\"MSE: {mse_raw:.2f}\")\n",
    "print(f\"RMSE: {rmse_raw:.2f}\")\n",
    "print(f\"R²: {r2_raw:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db8b47e2-e259-470b-9fce-3974ef5103de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN (con datos escalados)\n",
      "MAE: 0.04\n",
      "MSE: 0.00\n",
      "RMSE: 0.06\n",
      "R²: 0.8894\n"
     ]
    }
   ],
   "source": [
    "# Create model KNN after scaling\n",
    "knn_scaled = KNeighborsRegressor()\n",
    "\n",
    "# train with scaled data\n",
    "knn_scaled.fit(X_train_scaled, y_train)\n",
    "y_pred_knn_scaled = knn_scaled.predict(X_test_scaled)\n",
    "\n",
    "# compute metrics\n",
    "mae_scaled = mean_absolute_error(y_test, y_pred_knn_scaled)\n",
    "mse_scaled = mean_squared_error(y_test, y_pred_knn_scaled)\n",
    "rmse_scaled = np.sqrt(mse_scaled)\n",
    "r2_scaled = r2_score(y_test, y_pred_knn_scaled)\n",
    "\n",
    "print(\"KNN (con datos escalados)\")\n",
    "print(f\"MAE: {mae_scaled:.2f}\")\n",
    "print(f\"MSE: {mse_scaled:.2f}\")\n",
    "print(f\"RMSE: {rmse_scaled:.2f}\")\n",
    "print(f\"R²: {r2_scaled:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d5be99-2819-4584-9135-05f35123c214",
   "metadata": {},
   "source": [
    "### KNN Before vs After Scaling\n",
    "\n",
    "We tested the KNN model both before and after feature scaling.  \n",
    "Because the dataset had already been normalized during the cleaning phase (values between 0 and 1),  \n",
    "the results were almost identical (R² ≈ 0.89).  \n",
    "This confirms that the features were already scaled properly and no additional normalization was required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e499be83-c4d9-464b-aa20-49df93e469b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[1;32m      4\u001b[0m lin_reg \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLinear Regression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlin_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m               \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 32\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(name, model, X_train_scaled, X_test_scaled, X_train, X_test, y_train, y_test, use_scaled)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update global results without duplicates\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m results_df\n\u001b[0;32m---> 32\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m[results_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m name]  \u001b[38;5;66;03m# remove old row if it exists\u001b[39;00m\n\u001b[1;32m     34\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR²\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2\n\u001b[1;32m     40\u001b[0m }])\n\u001b[1;32m     42\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, new_row], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Linear Regression (after scaling)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "evaluate_model(\"Linear Regression\", lin_reg, \n",
    "               X_train_scaled, X_test_scaled, \n",
    "               X_train, X_test, \n",
    "               y_train, y_test, use_scaled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2575d78b-6318-4caa-ab40-c1ad2be98718",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[1;32m      6\u001b[0m bagging \u001b[38;5;241m=\u001b[39m BaggingRegressor(\n\u001b[1;32m      7\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mDecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),  \u001b[38;5;66;03m# ← cambio aquí\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      9\u001b[0m     bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,   \u001b[38;5;66;03m# True = Bagging (con reemplazo)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBagging (DecisionTree)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbagging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m               \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(name, model, X_train_scaled, X_test_scaled, X_train, X_test, y_train, y_test, use_scaled)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update global results without duplicates\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m results_df\n\u001b[0;32m---> 32\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m[results_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m name]  \u001b[38;5;66;03m# remove old row if it exists\u001b[39;00m\n\u001b[1;32m     34\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR²\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2\n\u001b[1;32m     40\u001b[0m }])\n\u001b[1;32m     42\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, new_row], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Bagging Regressor (before scaling)\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "bagging = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),  # ← cambio aquí\n",
    "    n_estimators=100,\n",
    "    bootstrap=True,   # True = Bagging (con reemplazo)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "evaluate_model(\"Bagging (DecisionTree)\", bagging,\n",
    "               X_train_scaled, X_test_scaled, \n",
    "               X_train, X_test,\n",
    "               y_train, y_test, use_scaled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "791704e4-e958-4160-b5ae-fb345f808755",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Pasting Regressor (before scaling)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pasting \u001b[38;5;241m=\u001b[39m BaggingRegressor(\n\u001b[1;32m      3\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mDecisionTreeRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),  \u001b[38;5;66;03m# ← cambio aquí también\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      5\u001b[0m     bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,   \u001b[38;5;66;03m# False = Pasting (sin reemplazo)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPasting (DecisionTree)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m               \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(name, model, X_train_scaled, X_test_scaled, X_train, X_test, y_train, y_test, use_scaled)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update global results without duplicates\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m results_df\n\u001b[0;32m---> 32\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m[results_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m name]  \u001b[38;5;66;03m# remove old row if it exists\u001b[39;00m\n\u001b[1;32m     34\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR²\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2\n\u001b[1;32m     40\u001b[0m }])\n\u001b[1;32m     42\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, new_row], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Pasting Regressor (before scaling)\n",
    "pasting = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(random_state=42),  # ← cambio aquí también\n",
    "    n_estimators=100,\n",
    "    bootstrap=False,   # False = Pasting (sin reemplazo)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "evaluate_model(\"Pasting (DecisionTree)\", pasting,\n",
    "               X_train_scaled, X_test_scaled, \n",
    "               X_train, X_test,\n",
    "               y_train, y_test, use_scaled=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141372f-25dd-466f-a325-2c030e3bf84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest (before scaling)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "evaluate_model(\"Random Forest\", rf,\n",
    "               X_train_scaled, X_test_scaled, \n",
    "               X_train, X_test,\n",
    "               y_train, y_test, use_scaled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6528ad8-0c5e-4ae4-91f7-240ed70edf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting (before scaling)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "evaluate_model(\"Gradient Boosting\", gbr,\n",
    "               X_train_scaled, X_test_scaled, \n",
    "               X_train, X_test,\n",
    "               y_train, y_test, use_scaled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17064cab-d57c-48dd-95d6-7f60a32bc370",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdaBoostRegressor\n\u001b[1;32m      4\u001b[0m ada \u001b[38;5;241m=\u001b[39m AdaBoostRegressor(\n\u001b[1;32m      5\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m      6\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m,\n\u001b[1;32m      7\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAdaBoost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mada\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m               \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m               \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_scaled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(name, model, X_train_scaled, X_test_scaled, X_train, X_test, y_train, y_test, use_scaled)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update global results without duplicates\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m results_df\n\u001b[0;32m---> 32\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mresults_df\u001b[49m[results_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m name]  \u001b[38;5;66;03m# remove old row if it exists\u001b[39;00m\n\u001b[1;32m     34\u001b[0m new_row \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m\"\u001b[39m: mae,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR²\u001b[39m\u001b[38;5;124m\"\u001b[39m: r2\n\u001b[1;32m     40\u001b[0m }])\n\u001b[1;32m     42\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, new_row], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "#Adaptive Boosting (AdaBoost) before scaling\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada = AdaBoostRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "evaluate_model(\"AdaBoost\", ada,\n",
    "               X_train_scaled, X_test_scaled, \n",
    "               X_train, X_test,\n",
    "               y_train, y_test, use_scaled=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1e42693-c3f4-402a-a64a-7c0e0fe0a447",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults_df\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR²\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "results_df.sort_values(by=\"R²\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530865f-b244-4b18-b67f-bebc18f3de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tmp = results_df.sort_values(by=\"R²\", ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(tmp[\"Model\"], tmp[\"R²\"])\n",
    "plt.title(\"Model Performance (R²)\")\n",
    "plt.xlabel(\"R²\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.barh(tmp[\"Model\"], tmp[\"RMSE\"])\n",
    "plt.title(\"Model Error (RMSE)\")\n",
    "plt.xlabel(\"RMSE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49e93c-c696-43ba-b5dc-c884c98241b7",
   "metadata": {},
   "source": [
    "### Model Evaluation Summary\n",
    "\n",
    "We evaluated several regression models to predict car selling prices.  \n",
    "The following metrics were used: **MAE**, **MSE**, **RMSE**, and **R²**.\n",
    "\n",
    "**Key findings:**\n",
    "- **Random Forest** achieved the best overall performance (R² = 0.93), indicating strong predictive power and stability.  \n",
    "- **Bagging (Decision Tree)** performed nearly as well, confirming the benefit of ensemble averaging.  \n",
    "- **Gradient Boosting** also showed robust performance, slightly below Random Forest.  \n",
    "- **Linear Regression** and **KNN** achieved decent but weaker results, as expected for non-ensemble methods.  \n",
    "- **AdaBoost** underperformed, possibly due to sensitivity to outliers and non-linear relationships.\n",
    "\n",
    "In conclusion, **Random Forest** was selected as the best model for further optimization (hyperparameter tuning) because it provides the best balance between bias and variance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
